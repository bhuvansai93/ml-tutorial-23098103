# ml-tutorial-23098103
# Understanding and Visualizing Decision Trees: How Depth Affects Model Performance

This project demonstrates how the depth of a Decision Tree affects its performance using the **Wine Quality** dataset. The tutorial is designed to be educational, interpretable, and reproducible, with supporting plots and models.

---

## ğŸ“ Project Structure

- `code-ml-tutorial-23098103.ipynb` â€“ Jupyter Notebook with full implementation
- `plots/` â€“ All visualizations used in the tutorial
- `decison-trees-tutorial-23098103.pdf` â€“ Written explanation (if not in notebook)
- `README.md` â€“ This file
- `LICENSE` â€“ Open-source license (MIT)

---

## ğŸ“Š What You'll Learn

- How Decision Tree depth impacts underfitting and overfitting
- How to convert a multiclass dataset into a binary classification task
- How to use `GridSearchCV` to tune hyperparameters
- How to visualize decision trees and interpret them
- How to use plots like heatmaps, accuracy graphs, and tree diagrams to communicate insights

---

## ğŸ“š Dataset

- **Wine Quality Dataset (Red wine)**  
  Source: UCI Machine Learning Repository  
  [https://archive.ics.uci.edu/ml/datasets/wine+quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)

---

## ğŸ§ª How to Run

1. Clone the repository  
   ```bash
   git clone https://github.com/bhuvansai93/code-ml-tutorial-23098103.git
   cd code-ml-tutorial-23098103

2. Install dependencies
  (We recommend using a virtual environment)
   ```bash
    pip install -r requirements.txt
3. Run the notebook
    ```bash
    jupyter notebook decision_tree_depth.ipynb
